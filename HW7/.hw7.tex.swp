\documentclass[10pt]{article}

\usepackage[margin=1.0in]{geometry}
\usepackage{url}
\usepackage{fancyhdr}
\pagestyle{fancy}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{sectsty}
\usepackage{amssymb}

\setlength\parindent{10pt}
\allowdisplaybreaks
\lhead{CSE 6331 HW1}
\chead{Melvyn Ian Drag}
\rhead{\today}



\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\sectionfont{\normalfont\sffamily\large}
\subsectionfont{\normalfont\sffamily\center\large\itshape}

\begin{document}
\section*{Problem 1}
\subsection*{Datastructures}
\begin{enumerate}
\item A hashset U of elements. 
\item Dictionary inSets := \{key = element: value = The indices of the sets which contain this element.\}
\item Dictionary sets := \{key = index: value = (Hashset of) elements in the set `index'. \}
\item Dictionary cardByIndex := \{key = index: value = cardinality of set `index' \}
\item Dictionary indexByCard := \{key = cardinality : value = indices of sets with this cardinality\}
\end{enumerate}
\subsection*{Algorithm in Text}
The idea of my algorithm is to maintain a dictionary of the number of sets of each cardinality. We will go through the sets of largest cardinality, and, one by one, add the set to the list of covers, delete all of the set's elements from U, and then check if U has been covered. If it hasn't been covered we have to update our data. We set the cardinality of the set to zero, and then go through its elements. For each element, we find which sets it was in and delete the element from those sets. Then we decrement the cardinalities of those sets. We then go back and grab another set of equally large cardinality as the first, until there are no more sets of the 'largest cardinality', at which point we decrement the 'largest cardinality', and begin looking  at subsets of smaller cardinality. 
\subsection*{Pseudocode}
\begin{algorithm}
\caption{Greedy Set Covering }\label{euclid}
\begin{algorithmic}[1]
\Procedure{SetCovering}{Arguments are the above mentioned datastructures.}
\State M $\gets$ $\max\limits_{index}$\{cardByIndex.value\}
\While {M $>$ 0}
\For{curr $\in$ indexByCard.value[M]}%%%
\State Add curr to T.
\For{el $\in$ sets[curr]} %
\State Delete el from \textit{U}
\EndFor %
\If {U == $\varnothing$}
\State Break
\Else
\State Delete curr from indexByCard[M]
\State Add curr to indexByCard[0]
\State cardByIndex[curr].value $\gets$ 0
\For{el $\in$ sets[curr]} %
\For{s$\in$ inSets[el]}%%
\State Delete el from sets[s].value
\State Decrement cardByIndex[s].value
\State Delete s from indexByCard[card].value
\State Add s to indexByCard[card - 1].value
\EndFor%%
\EndFor %
\EndIf
\EndFor%%%
\State Decrement M
\EndWhile
\State \Return T
\EndProcedure
\end{algorithmic}
\end{algorithm}
\subsection*{Complexity \& Correctness}
We are guaranteed the upperbound on complexity because finding the  max in line 3 can be done in the alloted time because in one double for loop over the sets and the elements in the sets ($\Theta(\sum\limits_{S\in F}|S|)$) we can find out the sets cardinality, find out which sets hold which elements, and see the elements of the sets. We need to receive the data in the structures I have mentioned, otherwise organizing the data will by itself take $\Theta(\sum\limits_{S\in F}|S|)$ time.

It takes unit time to for every operation which stores an element in one of the appropriate data structures. Then, the computation that occurs inside the main while loop will visit every element of U exactly once and in doing so, will remove the element from any set it is included in. Therefore, every element in every set that wil eventually form the finite cover is visited exactly once. Once again, the corresponding data structures can be updated in unit time for every element. 

Since we don't delete the elements from the other sets in F until we are sure that U is not empty, we can assert the upper bound. We might not need to visit every element from every set of S. 

\section*{Problem 2}
Our set must be covered by two sets. Imagine the set is cut into two halves and these halves are covered by subsets. Therefore OPT=2.
 

\section*{Problem 3}
Claim:
\begin{gather*}
1 + \sum\limits_{i=1}^{k}F_i = F_{k+2}
\end{gather*}
Verify:
\begin{gather*}
1 + \sum\limits_{i=1}^{k-1}F_i+F_k=F_{k+1} + F_k\\
1+\sum\limits_{i=1}^{k-1}F_i=F_{k+1}\dots\\
1+\sum\limits_{i=1}^1F_i=F_3\\
2=2
\end{gather*}
Furthermore
\begin{gather*}
F_{k+1} = F_k + F_{k-1} \ge   \sum\limits_{i=1}^kF_i 
\end{gather*}
Or you can flip the above on its head and it is a proof by induction. The Fibonacci sequence is monotonically increasing (strictly for $k\ge2$). Given the preceding observations, after $k-1$ combinations of elements we will have combined letters up to $a_k$, and the least weighted node/letter will be node $a_{k+1}$. The next lightest node/letter will be the node with weight $\frac{\sum\limits_{i=1}^kF_i}{\sum\limits_{i=1}^N}$ formed by merging the preceding lightest nodes (For proof see the above claim). 

One of two possible encodings has $a_1$ having $n-1$ zeros. For all other letters $a_k$, the encoding is $n-k$ zeros followed by a one. There other possible enconding switches $a_1$ and $a_2$, and the other encodings stay the same.
\end{document}
